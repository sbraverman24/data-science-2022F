{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost Classifier - The One that Worked the Best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of my imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtrain stands for train data\n",
    "dtrain = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# ftest stands for final test data\n",
    "ftest = pd.read_csv(\"test.csv\")\n",
    "\n",
    "dtrain.drop(\"Name\", axis=1, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting my features, train test splitting, making a list of all of the columns that have the data type \"object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dtrain.Transported\n",
    "features = ['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "X = dtrain[features]\n",
    "X2 = ftest[features]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y)\n",
    "\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding, Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahbraverman/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/sarahbraverman/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/sarahbraverman/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/sarahbraverman/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "OHcols = [\"CryoSleep\", \"VIP\", \"Destination\", \"HomePlanet\"]\n",
    "\n",
    "cols2 = [\"Cabin\", \"PassengerId\"]\n",
    "dtest2 = dtrain[cols2]\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "#Up here is changing the amount of rows\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[OHcols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[OHcols]))\n",
    "OH_cols_final = pd.DataFrame(OH_encoder.fit_transform(X2[OHcols]))\n",
    "\n",
    "# Putting the index back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "OH_cols_final.index = X2.index\n",
    "\n",
    "# Removing previous columns\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "num_final = X2.drop(object_cols, axis = 1)\n",
    "\n",
    "# Adding to my other columns\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_final = pd.concat([num_final, OH_cols_final], axis=1)\n",
    "\n",
    "# Imputing the numerical columns\n",
    "my_imputer = SimpleImputer()\n",
    "Mid_X_train = pd.DataFrame(my_imputer.fit_transform(OH_X_train))\n",
    "Mid_X_valid = pd.DataFrame(my_imputer.transform(OH_X_valid))\n",
    "Mid_final = pd.DataFrame(my_imputer.transform(OH_X_final))\n",
    "\n",
    "# Putting the column names back since imputation removed them\n",
    "Mid_X_train.columns = OH_X_train.columns\n",
    "Mid_X_valid.columns = OH_X_valid.columns\n",
    "Mid_final.columns = OH_X_final.columns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating my Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahbraverman/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(Mid_X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing some parameters and finding the best ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in [100, 125, 150, 200]:\n",
    "#     model = GradientBoostingClassifier(random_state = 1, max_depth = 4, n_estimators  = n)\n",
    "#     model.fit(Mid_X_train, y_train)\n",
    "#     preds_valid = model.predict(Mid_X_valid)\n",
    "#     print(n, accuracy_score(y_valid, preds_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training my final model and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahbraverman/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/sarahbraverman/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/sarahbraverman/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_final = pd.concat([Mid_X_valid, Mid_X_train])\n",
    "y_final = pd.concat([y_valid, y_train])\n",
    "model.predict(train_final)\n",
    "y_final.isna().sum()\n",
    "\n",
    "model_final = GradientBoostingClassifier(random_state = 1, max_depth = 4)\n",
    "model_final.fit(train_final, y_final)\n",
    "preds = model_final.predict(Mid_final)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputting my data into a csv to submit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\"PassengerId\": ftest.PassengerId, \"Transported\": preds})\n",
    "# output.to_csv('submission5.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1527\n",
    "Sarah Braverman\n",
    "0.79354\n",
    "Your Best Entry!\n",
    "Your most recent submission scored 0.79354, which is an improvement of your previous score of 0.79167. Great job!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82d6084fa52bbfe44e5d8bdc73d8f0ad601b91fd13e433e4ea3f469c7d7efe20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
